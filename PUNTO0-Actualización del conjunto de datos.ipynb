{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f57AJibYZhZ3"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary package\n",
        "import yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignoring warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "byrZctRTZ6B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the .download() method to get our data\n",
        "\n",
        "raw_data = yfinance.download (tickers = \"^GSPC ^FTSE ^N225 ^GDAXI\", start = \"1994-01-07\", end = \"2019-09-27\", interval = \"1d\", group_by = 'ticker', auto_adjust = True, threads = True)\n",
        "\n",
        "# tickers -> The time series we are interested in - (in our case, these are the S&P, FTSE, NIKKEI and DAX)\n",
        "# start -> The starting date of our data set\n",
        "# end -> The ending date of our data set (at the time of upload, this is the current date)\n",
        "# interval -> The distance in time between two recorded observations. Since we're using daily closing prices, we set it equal to \"1d\", which indicates 1 day.\n",
        "# group_by -> The way we want to group the scraped data. Usually we want it to be \"ticker\", so that we have all the information about a time series in 1 variable.\n",
        "# auto_adjust -> Automatically adjust the closing prices for each period.\n",
        "# treads - > Whether to use threads for mass downloading."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC3ltXZdZ6ty",
        "outputId": "821bdf78-a15e-4f95-de49-1ed23fd438f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a back up copy in case we remove/alter elements of the data by mistake\n",
        "df_comp = raw_data.copy()"
      ],
      "metadata": {
        "id": "R_QEsSGFZ61i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding new columns to the data set\n",
        "df_comp['spx'] = df_comp['^GSPC'].Close\n",
        "df_comp['dax'] = df_comp['^GDAXI'].Close\n",
        "df_comp['ftse'] = df_comp['^FTSE'].Close\n",
        "df_comp['nikkei'] = df_comp['^N225'].Close"
      ],
      "metadata": {
        "id": "3BCPhZcCZ66z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_comp = df_comp.iloc[1:] # Removing the first elements, since we always start 1 period before the first, due to time zone differences of closing prices\n",
        "del df_comp['^N225']  # Removing the original tickers of the data set\n",
        "del df_comp['^GSPC']\n",
        "del df_comp['^GDAXI']\n",
        "del df_comp['^FTSE']\n",
        "df_comp=df_comp.asfreq('b') # Setting the frequency of the data\n",
        "df_comp=df_comp.fillna(method='ffill') # Filling any missing values"
      ],
      "metadata": {
        "id": "HJxzXMfiZ7AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (df_comp.head()) # Displaying the first 5 elements to make sure the data was scraped correctly\n",
        "print (df_comp.tail()) # Making sure the last day we're including in th"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wq_V0ijaCC0",
        "outputId": "905315ae-4394-42b4-c050-3cc359e27839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   spx          dax         ftse        nikkei\n",
            "                                                              \n",
            "Date                                                          \n",
            "1994-01-10  475.269989  2225.000000  3440.600098  18443.439453\n",
            "1994-01-11  474.130005  2228.100098  3413.800049  18485.250000\n",
            "1994-01-12  474.170013  2182.060059  3372.000000  18793.880859\n",
            "1994-01-13  472.470001  2142.370117  3360.000000  18577.259766\n",
            "1994-01-14  474.910004  2151.050049  3400.600098  18973.699219\n",
            "                    spx           dax         ftse        nikkei\n",
            "                                                                \n",
            "Date                                                            \n",
            "2019-09-20  2992.070068  12468.009766  7344.899902  22079.089844\n",
            "2019-09-23  2991.780029  12342.330078  7326.100098  22079.089844\n",
            "2019-09-24  2966.600098  12307.150391  7291.399902  22098.839844\n",
            "2019-09-25  2984.870117  12234.179688  7290.000000  22020.150391\n",
            "2019-09-26  2977.620117  12288.540039  7351.100098  22048.240234\n"
          ]
        }
      ]
    }
  ]
}